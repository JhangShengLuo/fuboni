{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正規表達法斷句"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "article = '''\n",
    "\n",
    "【綜合報導】違建真害命！違建大火連續燒，近2周內，光雙北市至少有10人因密集隔間違建火警喪命，新北市府日前展開大動作，強拆一棟2層樓加蓋成6層樓、隔成158間房分租的離譜違建，強調明起全面執行頂加分租套房拆除。台北市長柯文哲昨也表示，考慮拿掉前市長陳水扁下的「違建特赦令」，涉及公安的大型違建，不論是既存違建或是新違建，都要依法處置。目前雙北共有29萬戶列管違建，若不改善，恐將面臨拆除命運。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\n【綜合報導】違建真害命',\n",
       " '違建大火連續燒',\n",
       " '近2周內',\n",
       " '光雙北市至少有10人因密集隔間違建火警喪命',\n",
       " '新北市府日前展開大動作',\n",
       " '強拆一棟2層樓加蓋成6層樓、隔成158間房分租的離譜違建',\n",
       " '強調明起全面執行頂加分租套房拆除',\n",
       " '台北市長柯文哲昨也表示',\n",
       " '考慮拿掉前市長陳水扁下的「違建特赦令」',\n",
       " '涉及公安的大型違建',\n",
       " '不論是既存違建或是新違建',\n",
       " '都要依法處置',\n",
       " '目前雙北共有29萬戶列管違建',\n",
       " '若不改善',\n",
       " '恐將面臨拆除命運',\n",
       " '\\n']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split('！|，|。',article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用Jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jieba in c:\\programdata\\anaconda3\\lib\\site-packages\n"
     ]
    }
   ],
   "source": [
    "! pip install jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\User\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.176 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大\n",
      "巨蛋\n",
      "案對\n",
      "市府\n",
      "同仁\n",
      "下\n",
      "封口令\n",
      "?\n",
      " \n",
      "柯\n",
      "P\n",
      "否認\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "for ele in jieba.cut('大巨蛋案對市府同仁下封口令? 柯P否認'):\n",
    "    print(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'大/巨蛋/案對/市府/同仁/下/封口令/?/ /柯/P/否認'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'/'.join(jieba.cut('大巨蛋案對市府同仁下封口令? 柯P否認'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'大/巨蛋/案/對/市府/同仁/下/封口/封口令/口令////柯/P/否/認'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'/'.join(jieba.cut('大巨蛋案對市府同仁下封口令? 柯P否認', cut_all=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'大/巨蛋/案對/市府/同仁/下/封口令/?/ /柯/P/否認'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'/'.join(jieba.cut('大巨蛋案對市府同仁下封口令? 柯P否認'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讀取使用者字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jieba.load_userdict('userdict.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'大巨蛋/案對/市府/同仁/下/封口令/?/ /柯P/否認'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'/'.join(jieba.cut('大巨蛋案對市府同仁下封口令? 柯P否認'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 抓出詞性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大巨蛋 n\n",
      "案 ng\n",
      "對 p\n",
      "市府 n\n",
      "同仁 nr\n",
      "下 f\n",
      "封口令 n\n",
      "? x\n",
      "  x\n",
      "柯P n\n",
      "否認 v\n"
     ]
    }
   ],
   "source": [
    "import jieba.posseg as pseg\n",
    "words = pseg.cut('大巨蛋案對市府同仁下封口令? 柯P否認')\n",
    "for w in words:\n",
    "    print(w.word, w.flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('大巨蛋', 0, 3)\n",
      "('案對', 3, 5)\n",
      "('市府', 5, 7)\n",
      "('同仁', 7, 9)\n",
      "('下', 9, 10)\n",
      "('封口令', 10, 13)\n",
      "('?', 13, 14)\n",
      "(' ', 14, 15)\n",
      "('柯P', 15, 17)\n",
      "('否認', 17, 19)\n"
     ]
    }
   ],
   "source": [
    "sentence = '大巨蛋案對市府同仁下封口令? 柯P否認'\n",
    "for tw in jieba.tokenize(sentence):\n",
    "    print(tw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['封口令']\n"
     ]
    }
   ],
   "source": [
    "import jieba.analyse\n",
    "tags = jieba.analyse.extract_tags(sentence, 1)\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['同仁']\n"
     ]
    }
   ],
   "source": [
    "import jieba.analyse\n",
    "tags = jieba.analyse.extract_tags(sentence, 1, allowPOS=['nr'])\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 擴充字典\n",
    "- https://www.moedict.tw/\n",
    "\n",
    "- https://zh.wikipedia.org/wiki/%E5%94%90%E7%B4%8D%E5%BE%B7%C2%B7%E5%B7%9D%E6%99%AE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用新聞關鍵字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "res = requests.get('http://news.ltn.com.tw/news/business/breakingnews/2272811')\n",
    "soup = BeautifulSoup(res.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keywords = [ele.text for ele in soup.select('.keyword a')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('userdict.txt', 'a', encoding='utf-8') as f:\n",
    "    f.write('\\n')\n",
    "    for keyword in keywords:\n",
    "        f.write(keyword + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 取得保險詞彙"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = 'https://www.ib.gov.tw/ch/home.jsp?id=59&parentpath=0,6&mcustomize='\n",
    "payload = {\n",
    "'id':'59',\n",
    "'contentid':'59',\n",
    "'parentpath':'0,6',\n",
    "'mcustomize':'bilingual_list.jsp',\n",
    "'ckeyword':'請輸入中文關鍵字',\n",
    "'ekeyword':'請輸入英文關鍵字',\n",
    "'page':'3'\n",
    "}\n",
    "\n",
    "res = requests.post(url, data = payload)\n",
    "\n",
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "keywords = [ele.text for ele in soup.select('.bich_name_con')]\n",
    "with open('userdict.txt', 'a', encoding='utf-8') as f:\n",
    "    f.write('\\n')\n",
    "    for keyword in keywords:\n",
    "        f.write(keyword + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將PDF 轉成文字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfminer3k in c:\\programdata\\anaconda3\\lib\\site-packages\n",
      "Requirement already satisfied: ply>=3.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from pdfminer3k)\n",
      "Requirement already satisfied: pytest>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pdfminer3k)\n",
      "Requirement already satisfied: py>=1.4.29 in c:\\programdata\\anaconda3\\lib\\site-packages (from pytest>=2.0->pdfminer3k)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from pytest>=2.0->pdfminer3k)\n"
     ]
    }
   ],
   "source": [
    "! pip install pdfminer3k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = requests.get('https://www.fubon.com/life/public_info/public_info_04/5-12.pdf')\n",
    "with open('fubon.pdf', 'wb') as f:\n",
    "    f.write(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## from pdfminer.pdfparser import PDFParser, PDFDocument\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "from pdfminer.layout import LAParams, LTTextBox, LTTextLine\n",
    "\n",
    "s = ''\n",
    "fp = open('fubon.pdf', 'rb')\n",
    "parser = PDFParser(fp)\n",
    "doc = PDFDocument()\n",
    "parser.set_document(doc)\n",
    "doc.set_parser(parser)\n",
    "doc.initialize('')\n",
    "rsrcmgr = PDFResourceManager()\n",
    "laparams = LAParams()\n",
    "device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n",
    "interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "# Process each page contained in the document.\n",
    "for page in doc.get_pages():\n",
    "    interpreter.process_page(page)\n",
    "    layout = device.get_result()\n",
    "    for lt_obj in layout:\n",
    "        if isinstance(lt_obj, LTTextBox) or isinstance(lt_obj, LTTextLine):\n",
    "            #print(lt_obj.get_text())\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將文字轉成 Word 檔案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-docx\n",
      "  Downloading python-docx-0.8.6.tar.gz (5.3MB)\n",
      "Requirement already satisfied: lxml>=2.3.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-docx)\n",
      "Building wheels for collected packages: python-docx\n",
      "  Running setup.py bdist_wheel for python-docx: started\n",
      "  Running setup.py bdist_wheel for python-docx: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\User\\AppData\\Local\\pip\\Cache\\wheels\\cc\\74\\10\\42b00d7d6a64cf21f194bfef9b94150009ada880f13c5b2ad3\n",
      "Successfully built python-docx\n",
      "Installing collected packages: python-docx\n",
      "Successfully installed python-docx-0.8.6\n"
     ]
    }
   ],
   "source": [
    "! pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\docx\\styles\\styles.py:54: UserWarning: style lookup by style_id is deprecated. Use style name as key instead.\n",
      "  warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "\n",
    "document = Document()\n",
    "\n",
    "document.add_heading('Document Title', 0)\n",
    "\n",
    "p = document.add_paragraph('A plain paragraph having some ')\n",
    "p.add_run('bold').bold = True\n",
    "p.add_run(' and some ')\n",
    "p.add_run('italic.').italic = True\n",
    "\n",
    "document.add_heading('Heading, level 1', level=1)\n",
    "document.add_paragraph('Intense quote', style='IntenseQuote')\n",
    "\n",
    "document.add_paragraph(\n",
    "    'first item in unordered list', style='ListBullet'\n",
    ")\n",
    "document.add_paragraph(\n",
    "    'first item in ordered list', style='ListNumber'\n",
    ")\n",
    "\n",
    "\n",
    "document.add_page_break()\n",
    "\n",
    "document.save('demo.docx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將PDF轉 WORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pdfminer.layout:Too many boxes (101) to group, skipping.\n"
     ]
    }
   ],
   "source": [
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "from pdfminer.layout import LAParams, LTTextBox, LTTextLine\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "\n",
    "document = Document()\n",
    "\n",
    "\n",
    "fp = open('fubon.pdf', 'rb')\n",
    "parser = PDFParser(fp)\n",
    "doc = PDFDocument()\n",
    "parser.set_document(doc)\n",
    "doc.set_parser(parser)\n",
    "doc.initialize('')\n",
    "rsrcmgr = PDFResourceManager()\n",
    "laparams = LAParams()\n",
    "device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n",
    "interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "# Process each page contained in the document.\n",
    "for page in doc.get_pages():\n",
    "    interpreter.process_page(page)\n",
    "    layout = device.get_result()\n",
    "    for lt_obj in layout:\n",
    "        if isinstance(lt_obj, LTTextBox) or isinstance(lt_obj, LTTextLine):\n",
    "            document.add_paragraph(lt_obj.get_text())\n",
    "    document.add_page_break()\n",
    "document.save('fubon.docx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NGRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence = '那我們酸民婉君也可以報名嗎'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'那我'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'我們'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "那我\n",
      "我們\n",
      "們酸\n",
      "酸民\n",
      "民婉\n",
      "婉君\n",
      "君也\n",
      "也可\n",
      "可以\n",
      "以報\n",
      "報名\n",
      "名嗎\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(sentence) - 2 + 1):\n",
    "    print(sentence[i:i+2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "那我們\n",
      "我們酸\n",
      "們酸民\n",
      "酸民婉\n",
      "民婉君\n",
      "婉君也\n",
      "君也可\n",
      "也可以\n",
      "可以報\n",
      "以報名\n",
      "報名嗎\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(sentence) - 3 + 1):\n",
    "    print(sentence[i:i+3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ngram(sentence, n = 2):\n",
    "    words = []\n",
    "    for i in range(0, len(sentence) - n + 1):\n",
    "        words.append(sentence[i:i+n])\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['那我們酸',\n",
       " '我們酸民',\n",
       " '們酸民婉',\n",
       " '酸民婉君',\n",
       " '民婉君也',\n",
       " '婉君也可',\n",
       " '君也可以',\n",
       " '也可以報',\n",
       " '可以報名',\n",
       " '以報名嗎']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram(sentence, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "news = '''\n",
    "全台最後一場週年慶今日由新光三越台北站前店壓軸登場，化妝品推出20萬組明星特惠組、保暖外套全面5折起，吸引上千民眾排隊搶購，館內一度塞車7分鐘。周末又有一波強烈冷氣團來襲，百貨業者看好禦寒商品、抗空污家電持續成長，預估首日來客數可達7萬人，業績上看4.5億元，成長1%。\n",
    " \n",
    "台北站前店店長曹龍生表示，今年化妝品表現最好，各品牌口紅都熱賣，年輕美眉也人手一支，為彩妝引進許多新客，帶動業績大幅成長。另外近來全台深受空污影響，讓空氣清淨機熱賣，如LG空氣清淨機大缺貨，家電新機種多優先在百貨開賣，搭配滿千送百更划算。\n",
    " \n",
    "冷氣團一波接著一波，毛料外套、羽絨被也相當受歡迎，如羽毛工房限量100件，開店不久即搶光。新光三越台北站前店推出話題大衣全面5折起，共計200櫃全面力拚比市場再低1折，500多件保暖外套平均1000~1500元；保暖冬被1折起。營業副理陳英玒看好在空污議題、低溫助攻下，家電業績可成長30%。\n",
    " \n",
    "民眾陳小姐表示今天以靴款為採買重點；從事行政的王小姐則主攻保養品、彩妝、香水，偏好在同一櫃買齊，折扣累積更划算，預算無上限；從事補教業的蒲先生同樣以購買保養品為主，保濕、眼霜、精華液等，大約花費1萬元。\n",
    " \n",
    "新光三越台北站前店今起至24日為期18天，首波強勢祭出超值禮券回饋，20日前化妝品滿2,000送200、全館滿5,000送500、大家電/法雅客滿萬送500、13日前加碼貴賓卡獨享大家電滿萬送仟。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00 13\n",
      "家電 5\n",
      "。\n",
      " 5\n",
      "台北 4\n",
      "北站 4\n",
      "站前 4\n",
      "前店 4\n",
      "20 4\n",
      "成長 4\n",
      "\n",
      "  4\n",
      " \n",
      " 4\n",
      "50 4\n",
      "新光 3\n",
      "光三 3\n",
      "三越 3\n",
      "越台 3\n",
      "化妝 3\n",
      "妝品 3\n",
      "保暖 3\n",
      "外套 3\n",
      "全面 3\n",
      "折起 3\n",
      "一波 3\n",
      "空污 3\n",
      "業績 3\n",
      "賣， 3\n",
      "0、 3\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "words = ngram(news, n = 2)\n",
    "words_dic = Counter(words)\n",
    "for k , v in words_dic.most_common(30):\n",
    "    if v >= 3:\n",
    "        print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "台北站 4\n",
      "北站前 4\n",
      "站前店 4\n",
      "。\n",
      "  4\n",
      "\n",
      " \n",
      " 4\n",
      "500 4\n",
      "新光三 3\n",
      "光三越 3\n",
      "三越台 3\n",
      "越台北 3\n",
      "化妝品 3\n",
      "000 3\n",
      "00、 3\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "words = ngram(news, n = 3)\n",
    "words_dic = Counter(words)\n",
    "for k , v in words_dic.most_common(30):\n",
    "    if v >= 3:\n",
    "        print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "台北站前 4\n",
      "北站前店 4\n",
      "。\n",
      " \n",
      " 4\n",
      "新光三越 3\n",
      "光三越台 3\n",
      "三越台北 3\n",
      "越台北站 3\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "words = ngram(news, n = 4)\n",
    "words_dic = Counter(words)\n",
    "for k , v in words_dic.most_common(30):\n",
    "    if v >= 3:\n",
    "        print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "全台最後一場週年慶今日由新光三越台北站前店壓軸登場\n",
      "化妝品推出20萬組明星特惠組\n",
      "保暖外套全面5折起\n",
      "吸引上千民眾排隊搶購\n",
      "館內一度塞車7分鐘\n",
      "周末又有一波強烈冷氣團來襲\n",
      "百貨業者看好禦寒商品\n",
      "抗空污家電持續成長\n",
      "預估首日來客數可達7萬人\n",
      "業績上看4.5億元\n",
      "成長1%\n",
      "\n",
      " \n",
      "台北站前店店長曹龍生表示\n",
      "今年化妝品表現最好\n",
      "各品牌口紅都熱賣\n",
      "年輕美眉也人手一支\n",
      "為彩妝引進許多新客\n",
      "帶動業績大幅成長\n",
      "另外近來全台深受空污影響\n",
      "讓空氣清淨機熱賣\n",
      "如LG空氣清淨機大缺貨\n",
      "家電新機種多優先在百貨開賣\n",
      "搭配滿千送百更划算\n",
      "\n",
      " \n",
      "冷氣團一波接著一波\n",
      "毛料外套\n",
      "羽絨被也相當受歡迎\n",
      "如羽毛工房限量100件\n",
      "開店不久即搶光\n",
      "新光三越台北站前店推出話題大衣全面5折起\n",
      "共計200櫃全面力拚比市場再低1折\n",
      "500多件保暖外套平均1000~1500元\n",
      "保暖冬被1折起\n",
      "營業副理陳英玒看好在空污議題\n",
      "低溫助攻下\n",
      "家電業績可成長30%\n",
      "\n",
      " \n",
      "民眾陳小姐表示今天以靴款為採買重點\n",
      "從事行政的王小姐則主攻保養品\n",
      "彩妝\n",
      "香水\n",
      "偏好在同一櫃買齊\n",
      "折扣累積更划算\n",
      "預算無上限\n",
      "從事補教業的蒲先生同樣以購買保養品為主\n",
      "保濕\n",
      "眼霜\n",
      "精華液等\n",
      "大約花費1萬元\n",
      "\n",
      " \n",
      "新光三越台北站前店今起至24日為期18天\n",
      "首波強勢祭出超值禮券回饋\n",
      "20日前化妝品滿2,000送200\n",
      "全館滿5,000送500\n",
      "大家電\n",
      "法雅客滿萬送500\n",
      "13日前加碼貴賓卡獨享大家電滿萬送仟\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "for ele in re.split('，|。|、|；|/', news):\n",
    "    print(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removeKey(sentence, keywords):\n",
    "    for keyword in keywords:\n",
    "        sentence = sentence.replace(keyword, '')\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removeKey2(sentence, keywords):\n",
    "    for keyword in keywords:\n",
    "        sentence = ''.join(sentence.split(keyword))\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n全台最後一場週年慶今日由台北站前店壓軸登場，推出20萬組明星特惠組、保暖外套全面5折起，吸引上千民眾排隊搶購，館內一度塞車7分鐘。周末又有一波強烈冷氣團來襲，百貨業者看好禦寒商品、抗空污家電持續成長，預估首日來客數可達7萬人，業績上看4.5億元，成長1%。\\n \\n台北站前店店長曹龍生表示，今年表現最好，各品牌口紅都熱賣，年輕美眉也人手一支，為彩妝引進許多新客，帶動業績大幅成長。另外近來全台深受空污影響，讓空氣清淨機熱賣，如LG空氣清淨機大缺貨，家電新機種多優先在百貨開賣，搭配滿千送百更划算。\\n \\n冷氣團一波接著一波，毛料外套、羽絨被也相當受歡迎，如羽毛工房限量100件，開店不久即搶光。台北站前店推出話題大衣全面5折起，共計200櫃全面力拚比市場再低1折，500多件保暖外套平均1000~1500元；保暖冬被1折起。營業副理陳英玒看好在空污議題、低溫助攻下，家電業績可成長30%。\\n \\n民眾陳小姐表示今天以靴款為採買重點；從事行政的王小姐則主攻保養品、彩妝、香水，偏好在同一櫃買齊，折扣累積更划算，預算無上限；從事補教業的蒲先生同樣以購買保養品為主，保濕、眼霜、精華液等，大約花費1萬元。\\n \\n台北站前店今起至24日為期18天，首波強勢祭出超值禮券回饋，20日前滿2,000送200、全館滿5,000送500、大家電/法雅客滿萬送500、13日前加碼貴賓卡獨享大家電滿萬送仟。\\n'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "removeKey(news, ['化妝品', '新光三越'])\n",
    "removeKey2(news, ['化妝品', '新光三越'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "全台最後一場週年慶今日由新光三越台北站前店壓軸登場\n",
      "化妝品推出20萬組明星特惠組\n",
      "保暖外套全面5折起\n",
      "吸引上千民眾排隊搶購\n",
      "館內一度塞車7分鐘\n",
      "周末又有一波強烈冷氣團來襲\n",
      "百貨業者看好禦寒商品\n",
      "抗空污家電持續成長\n",
      "預估首日來客數可達7萬人\n",
      "業績上看4.5億元\n",
      "成長1%\n",
      "\n",
      " \n",
      "台北站前店店長曹龍生表示\n",
      "今年化妝品表現最好\n",
      "各品牌口紅都熱賣\n",
      "年輕美眉也人手一支\n",
      "為彩妝引進許多新客\n",
      "帶動業績大幅成長\n",
      "另外近來全台深受空污影響\n",
      "讓空氣清淨機熱賣\n",
      "如LG空氣清淨機大缺貨\n",
      "家電新機種多優先在百貨開賣\n",
      "搭配滿千送百更划算\n",
      "\n",
      " \n",
      "冷氣團一波接著一波\n",
      "毛料外套\n",
      "羽絨被也相當受歡迎\n",
      "如羽毛工房限量100件\n",
      "開店不久即搶光\n",
      "新光三越台北站前店推出話題大衣全面5折起\n",
      "共計200櫃全面力拚比市場再低1折\n",
      "500多件保暖外套平均1000~1500元\n",
      "保暖冬被1折起\n",
      "營業副理陳英玒看好在空污議題\n",
      "低溫助攻下\n",
      "家電業績可成長30%\n",
      "\n",
      " \n",
      "民眾陳小姐表示今天以靴款為採買重點\n",
      "從事行政的王小姐則主攻保養品\n",
      "彩妝\n",
      "香水\n",
      "偏好在同一櫃買齊\n",
      "折扣累積更划算\n",
      "預算無上限\n",
      "從事補教業的蒲先生同樣以購買保養品為主\n",
      "保濕\n",
      "眼霜\n",
      "精華液等\n",
      "大約花費1萬元\n",
      "\n",
      " \n",
      "新光三越台北站前店今起至24日為期18天\n",
      "首波強勢祭出超值禮券回饋\n",
      "20日前化妝品滿2,000送200\n",
      "全館滿5,000送500\n",
      "大家電\n",
      "法雅客滿萬送500\n",
      "13日前加碼貴賓卡獨享大家電滿萬送仟\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "for ele in re.split('，|。|、|；|/', news):\n",
    "    print(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "sentenceAry = []\n",
    "for ele in re.split('，|。|、|；|/', news):\n",
    "    sentenceAry.append(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['台北站前店', '家電', '成長']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "keywords = []\n",
    "for term_length in range(5,1,-1):\n",
    "    ret = []\n",
    "    for sentence in sentenceAry:\n",
    "        s = removeKey(sentence, keywords)\n",
    "        ngram_words = ngram(s, term_length)\n",
    "        ret.extend(ngram_words)\n",
    "    c = Counter(ret)\n",
    "    for k, v in c.most_common():\n",
    "        m = re.match('[\\u4e00-\\u9fa5]+', k)\n",
    "        if v >= 4 and m:\n",
    "            keywords.append(k)\n",
    "            #print(keywords)\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
