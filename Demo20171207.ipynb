{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正規表達法斷句"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "article = '''\n",
    "\n",
    "【綜合報導】違建真害命！違建大火連續燒，近2周內，光雙北市至少有10人因密集隔間違建火警喪命，新北市府日前展開大動作，強拆一棟2層樓加蓋成6層樓、隔成158間房分租的離譜違建，強調明起全面執行頂加分租套房拆除。台北市長柯文哲昨也表示，考慮拿掉前市長陳水扁下的「違建特赦令」，涉及公安的大型違建，不論是既存違建或是新違建，都要依法處置。目前雙北共有29萬戶列管違建，若不改善，恐將面臨拆除命運。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\n【綜合報導】違建真害命',\n",
       " '違建大火連續燒',\n",
       " '近2周內',\n",
       " '光雙北市至少有10人因密集隔間違建火警喪命',\n",
       " '新北市府日前展開大動作',\n",
       " '強拆一棟2層樓加蓋成6層樓、隔成158間房分租的離譜違建',\n",
       " '強調明起全面執行頂加分租套房拆除',\n",
       " '台北市長柯文哲昨也表示',\n",
       " '考慮拿掉前市長陳水扁下的「違建特赦令」',\n",
       " '涉及公安的大型違建',\n",
       " '不論是既存違建或是新違建',\n",
       " '都要依法處置',\n",
       " '目前雙北共有29萬戶列管違建',\n",
       " '若不改善',\n",
       " '恐將面臨拆除命運',\n",
       " '\\n']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split('！|，|。',article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用Jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jieba in c:\\programdata\\anaconda3\\lib\\site-packages\n"
     ]
    }
   ],
   "source": [
    "! pip install jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\User\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.176 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大\n",
      "巨蛋\n",
      "案對\n",
      "市府\n",
      "同仁\n",
      "下\n",
      "封口令\n",
      "?\n",
      " \n",
      "柯\n",
      "P\n",
      "否認\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "for ele in jieba.cut('大巨蛋案對市府同仁下封口令? 柯P否認'):\n",
    "    print(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'大/巨蛋/案對/市府/同仁/下/封口令/?/ /柯/P/否認'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'/'.join(jieba.cut('大巨蛋案對市府同仁下封口令? 柯P否認'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'大/巨蛋/案/對/市府/同仁/下/封口/封口令/口令////柯/P/否/認'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'/'.join(jieba.cut('大巨蛋案對市府同仁下封口令? 柯P否認', cut_all=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'大/巨蛋/案對/市府/同仁/下/封口令/?/ /柯/P/否認'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'/'.join(jieba.cut('大巨蛋案對市府同仁下封口令? 柯P否認'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讀取使用者字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jieba.load_userdict('userdict.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'大巨蛋/案對/市府/同仁/下/封口令/?/ /柯P/否認'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'/'.join(jieba.cut('大巨蛋案對市府同仁下封口令? 柯P否認'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 抓出詞性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大巨蛋 n\n",
      "案 ng\n",
      "對 p\n",
      "市府 n\n",
      "同仁 nr\n",
      "下 f\n",
      "封口令 n\n",
      "? x\n",
      "  x\n",
      "柯P n\n",
      "否認 v\n"
     ]
    }
   ],
   "source": [
    "import jieba.posseg as pseg\n",
    "words = pseg.cut('大巨蛋案對市府同仁下封口令? 柯P否認')\n",
    "for w in words:\n",
    "    print(w.word, w.flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('大巨蛋', 0, 3)\n",
      "('案對', 3, 5)\n",
      "('市府', 5, 7)\n",
      "('同仁', 7, 9)\n",
      "('下', 9, 10)\n",
      "('封口令', 10, 13)\n",
      "('?', 13, 14)\n",
      "(' ', 14, 15)\n",
      "('柯P', 15, 17)\n",
      "('否認', 17, 19)\n"
     ]
    }
   ],
   "source": [
    "sentence = '大巨蛋案對市府同仁下封口令? 柯P否認'\n",
    "for tw in jieba.tokenize(sentence):\n",
    "    print(tw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['封口令']\n"
     ]
    }
   ],
   "source": [
    "import jieba.analyse\n",
    "tags = jieba.analyse.extract_tags(sentence, 1)\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['同仁']\n"
     ]
    }
   ],
   "source": [
    "import jieba.analyse\n",
    "tags = jieba.analyse.extract_tags(sentence, 1, allowPOS=['nr'])\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 擴充字典\n",
    "- https://www.moedict.tw/\n",
    "\n",
    "- https://zh.wikipedia.org/wiki/%E5%94%90%E7%B4%8D%E5%BE%B7%C2%B7%E5%B7%9D%E6%99%AE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用新聞關鍵字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "res = requests.get('http://news.ltn.com.tw/news/business/breakingnews/2272811')\n",
    "soup = BeautifulSoup(res.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keywords = [ele.text for ele in soup.select('.keyword a')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('userdict.txt', 'a', encoding='utf-8') as f:\n",
    "    f.write('\\n')\n",
    "    for keyword in keywords:\n",
    "        f.write(keyword + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 取得保險詞彙"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = 'https://www.ib.gov.tw/ch/home.jsp?id=59&parentpath=0,6&mcustomize='\n",
    "payload = {\n",
    "'id':'59',\n",
    "'contentid':'59',\n",
    "'parentpath':'0,6',\n",
    "'mcustomize':'bilingual_list.jsp',\n",
    "'ckeyword':'請輸入中文關鍵字',\n",
    "'ekeyword':'請輸入英文關鍵字',\n",
    "'page':'3'\n",
    "}\n",
    "\n",
    "res = requests.post(url, data = payload)\n",
    "\n",
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "keywords = [ele.text for ele in soup.select('.bich_name_con')]\n",
    "with open('userdict.txt', 'a', encoding='utf-8') as f:\n",
    "    f.write('\\n')\n",
    "    for keyword in keywords:\n",
    "        f.write(keyword + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將PDF 轉成文字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfminer3k in c:\\programdata\\anaconda3\\lib\\site-packages\n",
      "Requirement already satisfied: ply>=3.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from pdfminer3k)\n",
      "Requirement already satisfied: pytest>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pdfminer3k)\n",
      "Requirement already satisfied: py>=1.4.29 in c:\\programdata\\anaconda3\\lib\\site-packages (from pytest>=2.0->pdfminer3k)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from pytest>=2.0->pdfminer3k)\n"
     ]
    }
   ],
   "source": [
    "! pip install pdfminer3k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = requests.get('https://www.fubon.com/life/public_info/public_info_04/5-12.pdf')\n",
    "with open('fubon.pdf', 'wb') as f:\n",
    "    f.write(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## from pdfminer.pdfparser import PDFParser, PDFDocument\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "from pdfminer.layout import LAParams, LTTextBox, LTTextLine\n",
    "\n",
    "s = ''\n",
    "fp = open('fubon.pdf', 'rb')\n",
    "parser = PDFParser(fp)\n",
    "doc = PDFDocument()\n",
    "parser.set_document(doc)\n",
    "doc.set_parser(parser)\n",
    "doc.initialize('')\n",
    "rsrcmgr = PDFResourceManager()\n",
    "laparams = LAParams()\n",
    "device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n",
    "interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "# Process each page contained in the document.\n",
    "for page in doc.get_pages():\n",
    "    interpreter.process_page(page)\n",
    "    layout = device.get_result()\n",
    "    for lt_obj in layout:\n",
    "        if isinstance(lt_obj, LTTextBox) or isinstance(lt_obj, LTTextLine):\n",
    "            #print(lt_obj.get_text())\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將文字轉成 Word 檔案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-docx\n",
      "  Downloading python-docx-0.8.6.tar.gz (5.3MB)\n",
      "Requirement already satisfied: lxml>=2.3.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-docx)\n",
      "Building wheels for collected packages: python-docx\n",
      "  Running setup.py bdist_wheel for python-docx: started\n",
      "  Running setup.py bdist_wheel for python-docx: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\User\\AppData\\Local\\pip\\Cache\\wheels\\cc\\74\\10\\42b00d7d6a64cf21f194bfef9b94150009ada880f13c5b2ad3\n",
      "Successfully built python-docx\n",
      "Installing collected packages: python-docx\n",
      "Successfully installed python-docx-0.8.6\n"
     ]
    }
   ],
   "source": [
    "! pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\docx\\styles\\styles.py:54: UserWarning: style lookup by style_id is deprecated. Use style name as key instead.\n",
      "  warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "\n",
    "document = Document()\n",
    "\n",
    "document.add_heading('Document Title', 0)\n",
    "\n",
    "p = document.add_paragraph('A plain paragraph having some ')\n",
    "p.add_run('bold').bold = True\n",
    "p.add_run(' and some ')\n",
    "p.add_run('italic.').italic = True\n",
    "\n",
    "document.add_heading('Heading, level 1', level=1)\n",
    "document.add_paragraph('Intense quote', style='IntenseQuote')\n",
    "\n",
    "document.add_paragraph(\n",
    "    'first item in unordered list', style='ListBullet'\n",
    ")\n",
    "document.add_paragraph(\n",
    "    'first item in ordered list', style='ListNumber'\n",
    ")\n",
    "\n",
    "\n",
    "document.add_page_break()\n",
    "\n",
    "document.save('demo.docx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將PDF轉 WORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pdfminer.layout:Too many boxes (101) to group, skipping.\n"
     ]
    }
   ],
   "source": [
    "## from pdfminer.pdfparser import PDFParser, PDFDocument\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "from pdfminer.layout import LAParams, LTTextBox, LTTextLine\n",
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "\n",
    "document = Document()\n",
    "\n",
    "\n",
    "fp = open('fubon.pdf', 'rb')\n",
    "parser = PDFParser(fp)\n",
    "doc = PDFDocument()\n",
    "parser.set_document(doc)\n",
    "doc.set_parser(parser)\n",
    "doc.initialize('')\n",
    "rsrcmgr = PDFResourceManager()\n",
    "laparams = LAParams()\n",
    "device = PDFPageAggregator(rsrcmgr, laparams=laparams)\n",
    "interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "# Process each page contained in the document.\n",
    "for page in doc.get_pages():\n",
    "    interpreter.process_page(page)\n",
    "    layout = device.get_result()\n",
    "    for lt_obj in layout:\n",
    "        if isinstance(lt_obj, LTTextBox) or isinstance(lt_obj, LTTextLine):\n",
    "            document.add_paragraph(lt_obj.get_text())\n",
    "    document.add_page_break()\n",
    "document.save('fubon.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
